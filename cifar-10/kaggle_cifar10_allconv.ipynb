{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Kaggle][Cifar-10] All Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806) was the original paper that were the 2nd place in the Kaggle competition. This kernel was based on the Keras implementation found [here](https://github.com/MateLabs/All-Conv-Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 關於 Cifar-10 資料集\n",
    "\n",
    "CIFAR-10 資料集含有 60,000 張 32x32 彩色圖片，分為 10 類，每一類有 6000 張圖片。官方原始資料集的其中 50,000 張用來訓練，10,000 張用來測試。我們有保留原始資料集的訓練/測試分割。我們提供的檔案有：\n",
    "\n",
    "- train.7z - png 檔案格式的訓練圖片\n",
    "- test.7z - png 檔案格式的測試圖片\n",
    "- trainLabels.csv - 訓練圖片的標籤\n",
    "- sampleSubmission.csv - 提交答案的範例 (id, label)\n",
    "\n",
    "為了勸阻某些作弊的形式 (例如手動加標籤)，我們在測試圖片集另外添加了 290,000 張垃圾圖片。這些圖片在評分時會被忽略。我們也在官方的 10,000 張測試圖片上，進行了無關緊要的改圖，以防止有人會使用檔案雜湊值來做查找。這些圖片異動應該不會太過影響分數。你應該要對全部 300,000 張測試圖片給出預測標籤。\n",
    "\n",
    "資料集的圖片分作下列 10 個類別：\n",
    "\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck\n",
    "\n",
    "類別完全沒有重疊。汽車 (automobiles) 和卡車 (trucks) 沒有重疊。汽車 (Automobile) 包含sedans, SUVs, 以及類似的車輛。卡車 (Truck) 只包含大卡車。兩者都不包含小卡車。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neillee\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D, merge\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看是否用到 GPU\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料準備\n",
    "\n",
    "先使用 Keras 提供的資料集做訓練和驗證，然後再將模型套用到 Kaggle 的測試圖片上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 訓練與驗證資料的預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: images: (50000, 32, 32, 3)  labels: (50000, 1)\n",
      "val data: images: (10000, 32, 32, 3)  labels: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('train data:', 'images:', X_train.shape, \" labels:\", y_train.shape)\n",
    "print('val data:', 'images:', X_val.shape, ' labels:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val   = X_val.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert between textual labels and numerical classes.\n",
    "label_to_class = { 'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9 }\n",
    "class_to_label = [ 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 350\n",
    "\n",
    "rows, cols = 32, 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(10, (1, 1), padding='valid'))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = Adam(lr=0.0001)\n",
    "#opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "opt = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    lr = 0.01\n",
    "    if epoch >= 200:\n",
    "        lr = 0.001\n",
    "    elif epoch >= 250:\n",
    "        lr = 0.0001\n",
    "    elif epoch >= 300:\n",
    "        lr = 0.00001 \n",
    "    return lr\n",
    "\n",
    "best_weights_filepath = 'SavedModel/cifar10-cnn-allconv-best.hdf5'\n",
    "\n",
    "callbacks = [\n",
    "    LearningRateScheduler(lr_schedule),\n",
    "    #EarlyStopping(monitor='val_acc', patience=10),\n",
    "    ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "1563/1563 [==============================] - 463s 296ms/step - loss: 0.3680 - acc: 0.8731 - val_loss: 0.4176 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86920, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 2/350\n",
      "1563/1563 [==============================] - 471s 301ms/step - loss: 0.3659 - acc: 0.8726 - val_loss: 0.3953 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86920 to 0.87730, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 3/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.3574 - acc: 0.8770 - val_loss: 0.4748 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87730\n",
      "Epoch 4/350\n",
      "1563/1563 [==============================] - 477s 305ms/step - loss: 0.3512 - acc: 0.8770 - val_loss: 0.4273 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87730\n",
      "Epoch 5/350\n",
      "1563/1563 [==============================] - 471s 302ms/step - loss: 0.3523 - acc: 0.8797 - val_loss: 0.4245 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87730\n",
      "Epoch 6/350\n",
      "1563/1563 [==============================] - 477s 305ms/step - loss: 0.3436 - acc: 0.8805 - val_loss: 0.4401 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87730\n",
      "Epoch 7/350\n",
      "1563/1563 [==============================] - 477s 305ms/step - loss: 0.3409 - acc: 0.8808 - val_loss: 0.4504 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87730\n",
      "Epoch 8/350\n",
      "1563/1563 [==============================] - 465s 298ms/step - loss: 0.3396 - acc: 0.8823 - val_loss: 0.4032 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87730\n",
      "Epoch 9/350\n",
      "1563/1563 [==============================] - 450s 288ms/step - loss: 0.3376 - acc: 0.8845 - val_loss: 0.4277 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87730\n",
      "Epoch 10/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.3361 - acc: 0.8831 - val_loss: 0.4734 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87730\n",
      "Epoch 11/350\n",
      "1563/1563 [==============================] - 464s 297ms/step - loss: 0.3340 - acc: 0.8840 - val_loss: 0.3766 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87730 to 0.88080, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 12/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.3283 - acc: 0.8860 - val_loss: 0.3929 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.88080 to 0.88380, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 13/350\n",
      "1563/1563 [==============================] - 448s 287ms/step - loss: 0.3326 - acc: 0.8856 - val_loss: 0.3716 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.88380\n",
      "Epoch 14/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.3249 - acc: 0.8872 - val_loss: 0.3930 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.88380 to 0.88510, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 15/350\n",
      "1563/1563 [==============================] - 474s 303ms/step - loss: 0.3222 - acc: 0.8872 - val_loss: 0.4109 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.88510\n",
      "Epoch 16/350\n",
      "1563/1563 [==============================] - 470s 301ms/step - loss: 0.3161 - acc: 0.8903 - val_loss: 0.4238 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.88510\n",
      "Epoch 17/350\n",
      "1563/1563 [==============================] - 476s 304ms/step - loss: 0.3184 - acc: 0.8896 - val_loss: 0.4361 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.88510\n",
      "Epoch 18/350\n",
      "1563/1563 [==============================] - 470s 301ms/step - loss: 0.3205 - acc: 0.8882 - val_loss: 0.4127 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.88510\n",
      "Epoch 19/350\n",
      "1563/1563 [==============================] - 462s 295ms/step - loss: 0.3202 - acc: 0.8901 - val_loss: 0.4297 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88510\n",
      "Epoch 20/350\n",
      "1563/1563 [==============================] - 455s 291ms/step - loss: 0.3132 - acc: 0.8908 - val_loss: 0.4651 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88510\n",
      "Epoch 21/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.3054 - acc: 0.8933 - val_loss: 0.4913 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.88510\n",
      "Epoch 22/350\n",
      "1563/1563 [==============================] - 449s 287ms/step - loss: 0.3147 - acc: 0.8918 - val_loss: 0.4301 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.88510\n",
      "Epoch 23/350\n",
      "1563/1563 [==============================] - 474s 303ms/step - loss: 0.3070 - acc: 0.8940 - val_loss: 0.4454 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.88510\n",
      "Epoch 24/350\n",
      "1563/1563 [==============================] - 465s 297ms/step - loss: 0.3028 - acc: 0.8948 - val_loss: 0.4292 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.88510\n",
      "Epoch 25/350\n",
      "1563/1563 [==============================] - 476s 305ms/step - loss: 0.2997 - acc: 0.8965 - val_loss: 0.4362 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.88510\n",
      "Epoch 26/350\n",
      "1563/1563 [==============================] - 476s 304ms/step - loss: 0.3010 - acc: 0.8961 - val_loss: 0.4536 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.88510\n",
      "Epoch 27/350\n",
      "1563/1563 [==============================] - 455s 291ms/step - loss: 0.3045 - acc: 0.8957 - val_loss: 0.4626 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.88510\n",
      "Epoch 28/350\n",
      "1563/1563 [==============================] - 476s 304ms/step - loss: 0.3007 - acc: 0.8959 - val_loss: 0.4049 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.88510\n",
      "Epoch 29/350\n",
      "1563/1563 [==============================] - 450s 288ms/step - loss: 0.3000 - acc: 0.8952 - val_loss: 0.4628 - val_acc: 0.8761\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.88510\n",
      "Epoch 30/350\n",
      "1563/1563 [==============================] - 454s 291ms/step - loss: 0.2932 - acc: 0.8996 - val_loss: 0.3821 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.88510 to 0.88770, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 31/350\n",
      "1563/1563 [==============================] - 474s 303ms/step - loss: 0.2916 - acc: 0.8975 - val_loss: 0.4005 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.88770\n",
      "Epoch 32/350\n",
      "1563/1563 [==============================] - 473s 303ms/step - loss: 0.2943 - acc: 0.8980 - val_loss: 0.3997 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.88770\n",
      "Epoch 33/350\n",
      "1563/1563 [==============================] - 474s 303ms/step - loss: 0.2951 - acc: 0.8980 - val_loss: 0.4348 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.88770\n",
      "Epoch 34/350\n",
      "1563/1563 [==============================] - 470s 301ms/step - loss: 0.2969 - acc: 0.8960 - val_loss: 0.4045 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.88770 to 0.88830, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 35/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2897 - acc: 0.9015 - val_loss: 0.4057 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.88830\n",
      "Epoch 36/350\n",
      "1563/1563 [==============================] - 472s 302ms/step - loss: 0.2926 - acc: 0.8991 - val_loss: 0.4182 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.88830\n",
      "Epoch 37/350\n",
      "1563/1563 [==============================] - 473s 303ms/step - loss: 0.2935 - acc: 0.8986 - val_loss: 0.4811 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.88830\n",
      "Epoch 38/350\n",
      "1563/1563 [==============================] - 473s 303ms/step - loss: 0.2883 - acc: 0.9006 - val_loss: 0.4211 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.88830\n",
      "Epoch 39/350\n",
      "1563/1563 [==============================] - 473s 303ms/step - loss: 0.2881 - acc: 0.9001 - val_loss: 0.4122 - val_acc: 0.8923\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.88830 to 0.89230, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 40/350\n",
      "1563/1563 [==============================] - 464s 297ms/step - loss: 0.2867 - acc: 0.9006 - val_loss: 0.4023 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89230\n",
      "Epoch 41/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2876 - acc: 0.9002 - val_loss: 0.4260 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.89230\n",
      "Epoch 42/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2870 - acc: 0.8999 - val_loss: 0.4449 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89230\n",
      "Epoch 43/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2889 - acc: 0.9001 - val_loss: 0.4642 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89230\n",
      "Epoch 44/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2899 - acc: 0.9006 - val_loss: 0.4064 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89230\n",
      "Epoch 45/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2850 - acc: 0.9007 - val_loss: 0.4734 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89230\n",
      "Epoch 46/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2854 - acc: 0.9004 - val_loss: 0.4440 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.89230\n",
      "Epoch 47/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2790 - acc: 0.9020 - val_loss: 0.4842 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.89230\n",
      "Epoch 48/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2763 - acc: 0.9033 - val_loss: 0.4121 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.89230\n",
      "Epoch 49/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2800 - acc: 0.9036 - val_loss: 0.4465 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.89230\n",
      "Epoch 50/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2844 - acc: 0.9008 - val_loss: 0.3861 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.89230\n",
      "Epoch 51/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2832 - acc: 0.9026 - val_loss: 0.4624 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.89230\n",
      "Epoch 52/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2801 - acc: 0.9037 - val_loss: 0.4246 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.89230 to 0.89350, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 53/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2782 - acc: 0.9049 - val_loss: 0.4320 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.89350\n",
      "Epoch 54/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2795 - acc: 0.9043 - val_loss: 0.4450 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.89350\n",
      "Epoch 55/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2822 - acc: 0.9016 - val_loss: 0.4459 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.89350\n",
      "Epoch 56/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2813 - acc: 0.9031 - val_loss: 0.4133 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.89350\n",
      "Epoch 57/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2775 - acc: 0.9043 - val_loss: 0.4317 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.89350\n",
      "Epoch 58/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2797 - acc: 0.9049 - val_loss: 0.4415 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.89350\n",
      "Epoch 59/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2798 - acc: 0.9035 - val_loss: 0.4876 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.89350\n",
      "Epoch 60/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2780 - acc: 0.9047 - val_loss: 0.4996 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.89350\n",
      "Epoch 61/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2799 - acc: 0.9029 - val_loss: 0.5549 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.89350\n",
      "Epoch 62/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2806 - acc: 0.9037 - val_loss: 0.4520 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.89350\n",
      "Epoch 63/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2751 - acc: 0.9049 - val_loss: 0.4164 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.89350 to 0.89390, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 64/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2807 - acc: 0.9025 - val_loss: 0.4624 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.89390\n",
      "Epoch 65/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2773 - acc: 0.9051 - val_loss: 0.5101 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.89390\n",
      "Epoch 66/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2817 - acc: 0.9013 - val_loss: 0.4320 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.89390\n",
      "Epoch 67/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2773 - acc: 0.9041 - val_loss: 0.4483 - val_acc: 0.8869\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.89390\n",
      "Epoch 68/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2757 - acc: 0.9051 - val_loss: 0.4577 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.89390\n",
      "Epoch 69/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2783 - acc: 0.9038 - val_loss: 0.4385 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.89390\n",
      "Epoch 70/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2777 - acc: 0.9055 - val_loss: 0.4063 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.89390\n",
      "Epoch 71/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2793 - acc: 0.9053 - val_loss: 0.4421 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.89390\n",
      "Epoch 72/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2726 - acc: 0.9069 - val_loss: 0.4340 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.89390\n",
      "Epoch 73/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.2810 - acc: 0.9030 - val_loss: 0.3928 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.89390 to 0.89540, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 74/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2778 - acc: 0.9054 - val_loss: 0.3697 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.89540 to 0.89550, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 75/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2812 - acc: 0.9057 - val_loss: 0.4786 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.89550\n",
      "Epoch 76/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2771 - acc: 0.9039 - val_loss: 0.4599 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.89550\n",
      "Epoch 77/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2763 - acc: 0.9047 - val_loss: 0.4580 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.89550\n",
      "Epoch 78/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2731 - acc: 0.9058 - val_loss: 0.4482 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.89550\n",
      "Epoch 79/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2799 - acc: 0.9030 - val_loss: 0.4023 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.89550\n",
      "Epoch 80/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2837 - acc: 0.9009 - val_loss: 0.4387 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.89550\n",
      "Epoch 81/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2787 - acc: 0.9040 - val_loss: 0.4740 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.89550\n",
      "Epoch 82/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2773 - acc: 0.9037 - val_loss: 0.4396 - val_acc: 0.8871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00082: val_acc did not improve from 0.89550\n",
      "Epoch 83/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2805 - acc: 0.9036 - val_loss: 0.4327 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.89550\n",
      "Epoch 84/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2755 - acc: 0.9058 - val_loss: 0.4411 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.89550\n",
      "Epoch 85/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2745 - acc: 0.9066 - val_loss: 0.4343 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.89550\n",
      "Epoch 86/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2768 - acc: 0.9055 - val_loss: 0.4912 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.89550\n",
      "Epoch 87/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2727 - acc: 0.9057 - val_loss: 0.5316 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.89550\n",
      "Epoch 88/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2756 - acc: 0.9057 - val_loss: 0.4565 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.89550\n",
      "Epoch 89/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2743 - acc: 0.9053 - val_loss: 0.5212 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.89550\n",
      "Epoch 90/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2812 - acc: 0.9038 - val_loss: 0.4831 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.89550\n",
      "Epoch 91/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2736 - acc: 0.9071 - val_loss: 0.4068 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.89550\n",
      "Epoch 92/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2788 - acc: 0.9054 - val_loss: 0.4563 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.89550\n",
      "Epoch 93/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2736 - acc: 0.9058 - val_loss: 0.3955 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.89550 to 0.90120, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 94/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2830 - acc: 0.9041 - val_loss: 0.4124 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.90120\n",
      "Epoch 95/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2762 - acc: 0.9057 - val_loss: 0.4554 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.90120\n",
      "Epoch 96/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2778 - acc: 0.9055 - val_loss: 0.4220 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.90120\n",
      "Epoch 97/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2765 - acc: 0.9061 - val_loss: 0.4260 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.90120\n",
      "Epoch 98/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2781 - acc: 0.9037 - val_loss: 0.4186 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.90120\n",
      "Epoch 99/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2729 - acc: 0.9058 - val_loss: 0.5342 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.90120\n",
      "Epoch 100/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2747 - acc: 0.9064 - val_loss: 0.4440 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.90120\n",
      "Epoch 101/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2759 - acc: 0.9059 - val_loss: 0.5376 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.90120\n",
      "Epoch 102/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2770 - acc: 0.9060 - val_loss: 0.4434 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.90120\n",
      "Epoch 103/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2863 - acc: 0.9024 - val_loss: 0.4458 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.90120\n",
      "Epoch 104/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.2806 - acc: 0.9049 - val_loss: 0.4454 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.90120\n",
      "Epoch 105/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2828 - acc: 0.9043 - val_loss: 0.4166 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.90120\n",
      "Epoch 106/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2725 - acc: 0.9060 - val_loss: 0.4635 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.90120\n",
      "Epoch 107/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2740 - acc: 0.9060 - val_loss: 0.4763 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.90120\n",
      "Epoch 108/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2768 - acc: 0.9058 - val_loss: 0.4563 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.90120\n",
      "Epoch 109/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2731 - acc: 0.9070 - val_loss: 0.4821 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.90120\n",
      "Epoch 110/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2751 - acc: 0.9065 - val_loss: 0.5106 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.90120\n",
      "Epoch 111/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2766 - acc: 0.9052 - val_loss: 0.4301 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.90120\n",
      "Epoch 112/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2766 - acc: 0.9050 - val_loss: 0.5018 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.90120\n",
      "Epoch 113/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2855 - acc: 0.9026 - val_loss: 0.5440 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.90120\n",
      "Epoch 114/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2815 - acc: 0.9047 - val_loss: 0.4665 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.90120\n",
      "Epoch 115/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2795 - acc: 0.9048 - val_loss: 0.4361 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.90120\n",
      "Epoch 116/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2802 - acc: 0.9037 - val_loss: 0.4442 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.90120\n",
      "Epoch 117/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2821 - acc: 0.9033 - val_loss: 0.4918 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.90120\n",
      "Epoch 118/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2816 - acc: 0.9045 - val_loss: 0.4243 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.90120\n",
      "Epoch 119/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2790 - acc: 0.9053 - val_loss: 0.4405 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.90120\n",
      "Epoch 120/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2850 - acc: 0.9028 - val_loss: 0.4586 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.90120\n",
      "Epoch 121/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2755 - acc: 0.9056 - val_loss: 0.4948 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.90120\n",
      "Epoch 122/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2813 - acc: 0.9044 - val_loss: 0.5530 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.90120\n",
      "Epoch 123/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2792 - acc: 0.9040 - val_loss: 0.4921 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.90120\n",
      "Epoch 124/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2787 - acc: 0.9056 - val_loss: 0.4739 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.90120\n",
      "Epoch 125/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2866 - acc: 0.9022 - val_loss: 0.5051 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.90120\n",
      "Epoch 126/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2890 - acc: 0.9028 - val_loss: 0.4856 - val_acc: 0.8811\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.90120\n",
      "Epoch 127/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2922 - acc: 0.9013 - val_loss: 0.4570 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.90120\n",
      "Epoch 128/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2837 - acc: 0.9036 - val_loss: 0.4895 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.90120\n",
      "Epoch 129/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2888 - acc: 0.9034 - val_loss: 0.4731 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.90120\n",
      "Epoch 130/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2903 - acc: 0.9018 - val_loss: 0.4519 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.90120\n",
      "Epoch 131/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2844 - acc: 0.9026 - val_loss: 0.4830 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.90120\n",
      "Epoch 132/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2921 - acc: 0.9008 - val_loss: 0.4561 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.90120\n",
      "Epoch 133/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2853 - acc: 0.9032 - val_loss: 0.5133 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.90120\n",
      "Epoch 134/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2906 - acc: 0.9034 - val_loss: 0.4847 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.90120\n",
      "Epoch 135/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2961 - acc: 0.9004 - val_loss: 0.4509 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.90120\n",
      "Epoch 136/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.2777 - acc: 0.9064 - val_loss: 0.5137 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.90120\n",
      "Epoch 137/350\n",
      "1563/1563 [==============================] - 445s 284ms/step - loss: 0.2872 - acc: 0.9038 - val_loss: 0.4522 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.90120\n",
      "Epoch 138/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2831 - acc: 0.9052 - val_loss: 0.5661 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.90120\n",
      "Epoch 139/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2850 - acc: 0.9041 - val_loss: 0.4919 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.90120\n",
      "Epoch 140/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.2908 - acc: 0.9017 - val_loss: 0.4858 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.90120\n",
      "Epoch 141/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2823 - acc: 0.9047 - val_loss: 0.5142 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.90120\n",
      "Epoch 142/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2896 - acc: 0.9026 - val_loss: 0.4687 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.90120\n",
      "Epoch 143/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2880 - acc: 0.9029 - val_loss: 0.4494 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.90120\n",
      "Epoch 144/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2904 - acc: 0.9037 - val_loss: 0.5004 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.90120\n",
      "Epoch 145/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2899 - acc: 0.9010 - val_loss: 0.5050 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.90120\n",
      "Epoch 146/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2876 - acc: 0.9020 - val_loss: 0.4482 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.90120\n",
      "Epoch 147/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2886 - acc: 0.9019 - val_loss: 0.5079 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.90120\n",
      "Epoch 148/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2851 - acc: 0.9040 - val_loss: 0.5001 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.90120\n",
      "Epoch 149/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.2910 - acc: 0.9015 - val_loss: 0.4799 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.90120\n",
      "Epoch 150/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2887 - acc: 0.9014 - val_loss: 0.4675 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.90120\n",
      "Epoch 151/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2881 - acc: 0.9030 - val_loss: 0.5250 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.90120\n",
      "Epoch 152/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2890 - acc: 0.9011 - val_loss: 0.5721 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.90120\n",
      "Epoch 153/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2941 - acc: 0.8994 - val_loss: 0.4448 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.90120\n",
      "Epoch 154/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2900 - acc: 0.9016 - val_loss: 0.4699 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.90120\n",
      "Epoch 155/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2947 - acc: 0.9005 - val_loss: 0.5110 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.90120\n",
      "Epoch 156/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2913 - acc: 0.9025 - val_loss: 0.4452 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.90120\n",
      "Epoch 157/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2890 - acc: 0.9024 - val_loss: 0.4928 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.90120\n",
      "Epoch 158/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2925 - acc: 0.9010 - val_loss: 0.4759 - val_acc: 0.8872\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.90120\n",
      "Epoch 159/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2953 - acc: 0.9019 - val_loss: 0.4522 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.90120\n",
      "Epoch 160/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2919 - acc: 0.9039 - val_loss: 0.5071 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.90120\n",
      "Epoch 161/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.2896 - acc: 0.9029 - val_loss: 0.5011 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.90120\n",
      "Epoch 162/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2894 - acc: 0.9036 - val_loss: 0.4741 - val_acc: 0.8947\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.90120\n",
      "Epoch 163/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2998 - acc: 0.8979 - val_loss: 0.5028 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.90120\n",
      "Epoch 164/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2959 - acc: 0.9014 - val_loss: 0.4556 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.90120\n",
      "Epoch 165/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3044 - acc: 0.8988 - val_loss: 0.4884 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.90120\n",
      "Epoch 166/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2953 - acc: 0.9009 - val_loss: 0.5267 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.90120\n",
      "Epoch 167/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2990 - acc: 0.9011 - val_loss: 0.4873 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.90120\n",
      "Epoch 168/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2956 - acc: 0.9013 - val_loss: 0.4440 - val_acc: 0.8970\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.90120\n",
      "Epoch 169/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.2970 - acc: 0.8996 - val_loss: 0.5074 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.90120\n",
      "Epoch 170/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3032 - acc: 0.8979 - val_loss: 0.4920 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.90120\n",
      "Epoch 171/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2978 - acc: 0.8996 - val_loss: 0.4574 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.90120\n",
      "Epoch 172/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3043 - acc: 0.8985 - val_loss: 0.4716 - val_acc: 0.8869\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.90120\n",
      "Epoch 173/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2961 - acc: 0.9006 - val_loss: 0.4905 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.90120\n",
      "Epoch 174/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3005 - acc: 0.8990 - val_loss: 0.4810 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.90120\n",
      "Epoch 175/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2993 - acc: 0.8992 - val_loss: 0.5385 - val_acc: 0.8786\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.90120\n",
      "Epoch 176/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.2953 - acc: 0.9013 - val_loss: 0.4750 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.90120\n",
      "Epoch 177/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3026 - acc: 0.8991 - val_loss: 0.4688 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.90120\n",
      "Epoch 178/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2972 - acc: 0.8990 - val_loss: 0.4418 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.90120\n",
      "Epoch 179/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3017 - acc: 0.8998 - val_loss: 0.4797 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.90120\n",
      "Epoch 180/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3096 - acc: 0.8959 - val_loss: 0.4722 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.90120\n",
      "Epoch 181/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3026 - acc: 0.8979 - val_loss: 0.4538 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.90120\n",
      "Epoch 182/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.2999 - acc: 0.9007 - val_loss: 0.5250 - val_acc: 0.8828\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.90120\n",
      "Epoch 183/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3017 - acc: 0.8984 - val_loss: 0.5171 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.90120\n",
      "Epoch 184/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3035 - acc: 0.8995 - val_loss: 0.4929 - val_acc: 0.8769\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.90120\n",
      "Epoch 185/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3076 - acc: 0.8957 - val_loss: 0.5347 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.90120\n",
      "Epoch 186/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3080 - acc: 0.8967 - val_loss: 0.5395 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.90120\n",
      "Epoch 187/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3079 - acc: 0.8974 - val_loss: 0.4896 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.90120\n",
      "Epoch 188/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3082 - acc: 0.8971 - val_loss: 0.5192 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.90120\n",
      "Epoch 189/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3044 - acc: 0.8969 - val_loss: 0.5195 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.90120\n",
      "Epoch 190/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.3070 - acc: 0.8978 - val_loss: 0.4937 - val_acc: 0.8947\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.90120\n",
      "Epoch 191/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.3088 - acc: 0.8972 - val_loss: 0.4815 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.90120\n",
      "Epoch 192/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3001 - acc: 0.8985 - val_loss: 0.4143 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.90120\n",
      "Epoch 193/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3074 - acc: 0.8961 - val_loss: 0.5531 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.90120\n",
      "Epoch 194/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3090 - acc: 0.8966 - val_loss: 0.5166 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.90120\n",
      "Epoch 195/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3097 - acc: 0.8953 - val_loss: 0.5335 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.90120\n",
      "Epoch 196/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3048 - acc: 0.8987 - val_loss: 0.4871 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.90120\n",
      "Epoch 197/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3074 - acc: 0.8972 - val_loss: 0.5011 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.90120\n",
      "Epoch 198/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3060 - acc: 0.8963 - val_loss: 0.4607 - val_acc: 0.8988\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.90120\n",
      "Epoch 199/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.3141 - acc: 0.8957 - val_loss: 0.5298 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.90120\n",
      "Epoch 200/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.3069 - acc: 0.8989 - val_loss: 0.4755 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.90120\n",
      "Epoch 201/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.2218 - acc: 0.9245 - val_loss: 0.4267 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00201: val_acc improved from 0.90120 to 0.90390, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 202/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1924 - acc: 0.9338 - val_loss: 0.4207 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00202: val_acc improved from 0.90390 to 0.90720, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 203/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1885 - acc: 0.9357 - val_loss: 0.4070 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00203: val_acc improved from 0.90720 to 0.91070, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 204/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1859 - acc: 0.9356 - val_loss: 0.3892 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00204: val_acc improved from 0.91070 to 0.91270, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 205/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1736 - acc: 0.9399 - val_loss: 0.4133 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.91270\n",
      "Epoch 206/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1689 - acc: 0.9421 - val_loss: 0.4106 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00206: val_acc improved from 0.91270 to 0.91290, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 207/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1670 - acc: 0.9422 - val_loss: 0.4088 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.91290\n",
      "Epoch 208/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1654 - acc: 0.9429 - val_loss: 0.3896 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00208: val_acc improved from 0.91290 to 0.91380, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 209/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1607 - acc: 0.9446 - val_loss: 0.3948 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00209: val_acc improved from 0.91380 to 0.91580, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 210/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1593 - acc: 0.9450 - val_loss: 0.4110 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.91580\n",
      "Epoch 211/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1586 - acc: 0.9457 - val_loss: 0.4027 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.91580\n",
      "Epoch 212/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1520 - acc: 0.9473 - val_loss: 0.3978 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.91580\n",
      "Epoch 213/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.1572 - acc: 0.9466 - val_loss: 0.3930 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.91580\n",
      "Epoch 214/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1482 - acc: 0.9478 - val_loss: 0.4126 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.91580\n",
      "Epoch 215/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1496 - acc: 0.9480 - val_loss: 0.4002 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00215: val_acc improved from 0.91580 to 0.91650, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 216/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1479 - acc: 0.9497 - val_loss: 0.4039 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.91650\n",
      "Epoch 217/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1491 - acc: 0.9475 - val_loss: 0.3903 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.91650\n",
      "Epoch 218/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1443 - acc: 0.9503 - val_loss: 0.3971 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.91650\n",
      "Epoch 219/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1432 - acc: 0.9503 - val_loss: 0.3923 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00219: val_acc improved from 0.91650 to 0.91770, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 220/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1393 - acc: 0.9512 - val_loss: 0.4062 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00220: val_acc improved from 0.91770 to 0.91780, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 221/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1399 - acc: 0.9519 - val_loss: 0.3819 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00221: val_acc improved from 0.91780 to 0.91900, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 222/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1407 - acc: 0.9513 - val_loss: 0.3932 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.91900\n",
      "Epoch 223/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1380 - acc: 0.9519 - val_loss: 0.3951 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00223: val_acc improved from 0.91900 to 0.91920, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 224/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1354 - acc: 0.9534 - val_loss: 0.4022 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.91920\n",
      "Epoch 225/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1371 - acc: 0.9516 - val_loss: 0.3863 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.91920\n",
      "Epoch 226/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1365 - acc: 0.9525 - val_loss: 0.3967 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.91920\n",
      "Epoch 227/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1341 - acc: 0.9528 - val_loss: 0.4230 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.91920\n",
      "Epoch 228/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1376 - acc: 0.9526 - val_loss: 0.3935 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.91920\n",
      "Epoch 229/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1325 - acc: 0.9538 - val_loss: 0.3957 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.91920\n",
      "Epoch 230/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1328 - acc: 0.9535 - val_loss: 0.4191 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.91920\n",
      "Epoch 231/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1350 - acc: 0.9531 - val_loss: 0.3907 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.91920\n",
      "Epoch 232/350\n",
      "1563/1563 [==============================] - 445s 284ms/step - loss: 0.1336 - acc: 0.9542 - val_loss: 0.3868 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.91920\n",
      "Epoch 233/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1310 - acc: 0.9547 - val_loss: 0.3864 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00233: val_acc improved from 0.91920 to 0.92020, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 234/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1313 - acc: 0.9551 - val_loss: 0.3939 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.92020\n",
      "Epoch 235/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1323 - acc: 0.9549 - val_loss: 0.3868 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.92020\n",
      "Epoch 236/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1297 - acc: 0.9549 - val_loss: 0.4074 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.92020\n",
      "Epoch 237/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1310 - acc: 0.9536 - val_loss: 0.3946 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.92020\n",
      "Epoch 238/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1261 - acc: 0.9557 - val_loss: 0.4065 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.92020\n",
      "Epoch 239/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1291 - acc: 0.9549 - val_loss: 0.3992 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.92020\n",
      "Epoch 240/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1245 - acc: 0.9567 - val_loss: 0.4152 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.92020\n",
      "Epoch 241/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1253 - acc: 0.9564 - val_loss: 0.4207 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.92020\n",
      "Epoch 242/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1253 - acc: 0.9555 - val_loss: 0.3960 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.92020\n",
      "Epoch 243/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1220 - acc: 0.9563 - val_loss: 0.4106 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.92020\n",
      "Epoch 244/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1244 - acc: 0.9571 - val_loss: 0.4048 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.92020\n",
      "Epoch 245/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1241 - acc: 0.9568 - val_loss: 0.4074 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.92020\n",
      "Epoch 246/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1220 - acc: 0.9573 - val_loss: 0.3896 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.92020\n",
      "Epoch 247/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1222 - acc: 0.9581 - val_loss: 0.4000 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.92020\n",
      "Epoch 248/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1215 - acc: 0.9578 - val_loss: 0.3954 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.92020\n",
      "Epoch 249/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1218 - acc: 0.9571 - val_loss: 0.3946 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.92020\n",
      "Epoch 250/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1206 - acc: 0.9582 - val_loss: 0.3989 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.92020\n",
      "Epoch 251/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1189 - acc: 0.9584 - val_loss: 0.3964 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.92020\n",
      "Epoch 252/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1189 - acc: 0.9580 - val_loss: 0.4159 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.92020\n",
      "Epoch 253/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1167 - acc: 0.9605 - val_loss: 0.3954 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.92020\n",
      "Epoch 254/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1163 - acc: 0.9589 - val_loss: 0.3695 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00254: val_acc improved from 0.92020 to 0.92270, saving model to SavedModel/cifar10-cnn-allconv-best.hdf5\n",
      "Epoch 255/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1175 - acc: 0.9595 - val_loss: 0.4214 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.92270\n",
      "Epoch 256/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1217 - acc: 0.9576 - val_loss: 0.4007 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.92270\n",
      "Epoch 257/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1172 - acc: 0.9589 - val_loss: 0.4040 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.92270\n",
      "Epoch 258/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1139 - acc: 0.9600 - val_loss: 0.4285 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.92270\n",
      "Epoch 259/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.1162 - acc: 0.9600 - val_loss: 0.4119 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.92270\n",
      "Epoch 260/350\n",
      "1563/1563 [==============================] - 447s 286ms/step - loss: 0.1178 - acc: 0.9597 - val_loss: 0.4108 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.92270\n",
      "Epoch 261/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1177 - acc: 0.9588 - val_loss: 0.4020 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.92270\n",
      "Epoch 262/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1157 - acc: 0.9588 - val_loss: 0.4128 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.92270\n",
      "Epoch 263/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1140 - acc: 0.9597 - val_loss: 0.4111 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.92270\n",
      "Epoch 264/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.1148 - acc: 0.9594 - val_loss: 0.4115 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.92270\n",
      "Epoch 265/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1138 - acc: 0.9600 - val_loss: 0.3966 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.92270\n",
      "Epoch 266/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1161 - acc: 0.9591 - val_loss: 0.3890 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.92270\n",
      "Epoch 267/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1132 - acc: 0.9600 - val_loss: 0.4012 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.92270\n",
      "Epoch 268/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.1090 - acc: 0.9608 - val_loss: 0.3991 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.92270\n",
      "Epoch 269/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1090 - acc: 0.9611 - val_loss: 0.4198 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.92270\n",
      "Epoch 270/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1086 - acc: 0.9618 - val_loss: 0.4340 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.92270\n",
      "Epoch 271/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1092 - acc: 0.9625 - val_loss: 0.4194 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.92270\n",
      "Epoch 272/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1074 - acc: 0.9619 - val_loss: 0.4112 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.92270\n",
      "Epoch 273/350\n",
      "1563/1563 [==============================] - 445s 284ms/step - loss: 0.1106 - acc: 0.9610 - val_loss: 0.3949 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.92270\n",
      "Epoch 274/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1120 - acc: 0.9608 - val_loss: 0.3938 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.92270\n",
      "Epoch 275/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1084 - acc: 0.9605 - val_loss: 0.4259 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.92270\n",
      "Epoch 276/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1071 - acc: 0.9619 - val_loss: 0.4246 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.92270\n",
      "Epoch 277/350\n",
      "1563/1563 [==============================] - 445s 284ms/step - loss: 0.1084 - acc: 0.9620 - val_loss: 0.4123 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.92270\n",
      "Epoch 278/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1101 - acc: 0.9621 - val_loss: 0.4055 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.92270\n",
      "Epoch 279/350\n",
      "1563/1563 [==============================] - 445s 284ms/step - loss: 0.1070 - acc: 0.9631 - val_loss: 0.4331 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.92270\n",
      "Epoch 280/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1087 - acc: 0.9621 - val_loss: 0.4158 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.92270\n",
      "Epoch 281/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1062 - acc: 0.9630 - val_loss: 0.4244 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.92270\n",
      "Epoch 282/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1083 - acc: 0.9623 - val_loss: 0.4026 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.92270\n",
      "Epoch 283/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1050 - acc: 0.9632 - val_loss: 0.4081 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.92270\n",
      "Epoch 284/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1040 - acc: 0.9628 - val_loss: 0.4285 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.92270\n",
      "Epoch 285/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1088 - acc: 0.9620 - val_loss: 0.4123 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.92270\n",
      "Epoch 286/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1067 - acc: 0.9635 - val_loss: 0.3981 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.92270\n",
      "Epoch 287/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1074 - acc: 0.9621 - val_loss: 0.4111 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.92270\n",
      "Epoch 288/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1073 - acc: 0.9625 - val_loss: 0.4098 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.92270\n",
      "Epoch 289/350\n",
      "1563/1563 [==============================] - 445s 284ms/step - loss: 0.1066 - acc: 0.9631 - val_loss: 0.4067 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.92270\n",
      "Epoch 290/350\n",
      "1563/1563 [==============================] - 445s 285ms/step - loss: 0.1033 - acc: 0.9636 - val_loss: 0.4082 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.92270\n",
      "Epoch 291/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1032 - acc: 0.9639 - val_loss: 0.4249 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.92270\n",
      "Epoch 292/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1001 - acc: 0.9650 - val_loss: 0.4148 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.92270\n",
      "Epoch 293/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1028 - acc: 0.9634 - val_loss: 0.4291 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.92270\n",
      "Epoch 294/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1031 - acc: 0.9645 - val_loss: 0.4042 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.92270\n",
      "Epoch 295/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1038 - acc: 0.9636 - val_loss: 0.4215 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.92270\n",
      "Epoch 296/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1037 - acc: 0.9637 - val_loss: 0.4062 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.92270\n",
      "Epoch 297/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.0992 - acc: 0.9640 - val_loss: 0.4407 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.92270\n",
      "Epoch 298/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1021 - acc: 0.9645 - val_loss: 0.4222 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.92270\n",
      "Epoch 299/350\n",
      "1563/1563 [==============================] - 446s 286ms/step - loss: 0.1056 - acc: 0.9627 - val_loss: 0.4027 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.92270\n",
      "Epoch 300/350\n",
      "1563/1563 [==============================] - 446s 285ms/step - loss: 0.1001 - acc: 0.9651 - val_loss: 0.4109 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.92270\n",
      "Epoch 301/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1044 - acc: 0.9625 - val_loss: 0.4162 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.92270\n",
      "Epoch 302/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1015 - acc: 0.9638 - val_loss: 0.4256 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.92270\n",
      "Epoch 303/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1017 - acc: 0.9638 - val_loss: 0.3982 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.92270\n",
      "Epoch 304/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1013 - acc: 0.9646 - val_loss: 0.4291 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.92270\n",
      "Epoch 305/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.1023 - acc: 0.9646 - val_loss: 0.4007 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.92270\n",
      "Epoch 306/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0986 - acc: 0.9651 - val_loss: 0.4239 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.92270\n",
      "Epoch 307/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0999 - acc: 0.9647 - val_loss: 0.4090 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.92270\n",
      "Epoch 308/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0993 - acc: 0.9648 - val_loss: 0.4179 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00308: val_acc did not improve from 0.92270\n",
      "Epoch 309/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0967 - acc: 0.9659 - val_loss: 0.4141 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.92270\n",
      "Epoch 310/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0993 - acc: 0.9648 - val_loss: 0.4134 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.92270\n",
      "Epoch 311/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0959 - acc: 0.9666 - val_loss: 0.4206 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.92270\n",
      "Epoch 312/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0999 - acc: 0.9647 - val_loss: 0.4022 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.92270\n",
      "Epoch 313/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0952 - acc: 0.9666 - val_loss: 0.4116 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.92270\n",
      "Epoch 314/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0999 - acc: 0.9654 - val_loss: 0.4167 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.92270\n",
      "Epoch 315/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0987 - acc: 0.9651 - val_loss: 0.4069 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.92270\n",
      "Epoch 316/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0984 - acc: 0.9658 - val_loss: 0.4062 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00316: val_acc did not improve from 0.92270\n",
      "Epoch 317/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0958 - acc: 0.9671 - val_loss: 0.3982 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.92270\n",
      "Epoch 318/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0934 - acc: 0.9677 - val_loss: 0.4264 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.92270\n",
      "Epoch 319/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0962 - acc: 0.9666 - val_loss: 0.4157 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.92270\n",
      "Epoch 320/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0930 - acc: 0.9663 - val_loss: 0.3970 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.92270\n",
      "Epoch 321/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0926 - acc: 0.9682 - val_loss: 0.4214 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.92270\n",
      "Epoch 322/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0968 - acc: 0.9659 - val_loss: 0.4324 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.92270\n",
      "Epoch 323/350\n",
      "1563/1563 [==============================] - 443s 283ms/step - loss: 0.0956 - acc: 0.9670 - val_loss: 0.4218 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.92270\n",
      "Epoch 324/350\n",
      "1563/1563 [==============================] - 473s 303ms/step - loss: 0.0964 - acc: 0.9665 - val_loss: 0.4295 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.92270\n",
      "Epoch 325/350\n",
      "1563/1563 [==============================] - 463s 296ms/step - loss: 0.0968 - acc: 0.9669 - val_loss: 0.4099 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.92270\n",
      "Epoch 326/350\n",
      "1563/1563 [==============================] - 476s 305ms/step - loss: 0.0953 - acc: 0.9669 - val_loss: 0.4025 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.92270\n",
      "Epoch 327/350\n",
      "1563/1563 [==============================] - 455s 291ms/step - loss: 0.0961 - acc: 0.9666 - val_loss: 0.4039 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.92270\n",
      "Epoch 328/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0922 - acc: 0.9680 - val_loss: 0.4185 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.92270\n",
      "Epoch 329/350\n",
      "1563/1563 [==============================] - 478s 306ms/step - loss: 0.0907 - acc: 0.9683 - val_loss: 0.4262 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.92270\n",
      "Epoch 330/350\n",
      "1563/1563 [==============================] - 466s 298ms/step - loss: 0.0930 - acc: 0.9674 - val_loss: 0.4219 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.92270\n",
      "Epoch 331/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.0922 - acc: 0.9675 - val_loss: 0.4050 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00331: val_acc did not improve from 0.92270\n",
      "Epoch 332/350\n",
      "1563/1563 [==============================] - 443s 284ms/step - loss: 0.0924 - acc: 0.9671 - val_loss: 0.4186 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.92270\n",
      "Epoch 333/350\n",
      "1563/1563 [==============================] - 461s 295ms/step - loss: 0.0939 - acc: 0.9668 - val_loss: 0.4300 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.92270\n",
      "Epoch 334/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 478s 306ms/step - loss: 0.0958 - acc: 0.9663 - val_loss: 0.4275 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.92270\n",
      "Epoch 335/350\n",
      "1563/1563 [==============================] - 478s 306ms/step - loss: 0.0936 - acc: 0.9679 - val_loss: 0.4044 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00335: val_acc did not improve from 0.92270\n",
      "Epoch 336/350\n",
      "1563/1563 [==============================] - 481s 308ms/step - loss: 0.0958 - acc: 0.9663 - val_loss: 0.4172 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.92270\n",
      "Epoch 337/350\n",
      "1563/1563 [==============================] - 481s 308ms/step - loss: 0.0910 - acc: 0.9685 - val_loss: 0.4137 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.92270\n",
      "Epoch 338/350\n",
      "1563/1563 [==============================] - 475s 304ms/step - loss: 0.0926 - acc: 0.9670 - val_loss: 0.4406 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.92270\n",
      "Epoch 339/350\n",
      "1563/1563 [==============================] - 469s 300ms/step - loss: 0.0918 - acc: 0.9681 - val_loss: 0.4287 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.92270\n",
      "Epoch 340/350\n",
      "1563/1563 [==============================] - 455s 291ms/step - loss: 0.0914 - acc: 0.9686 - val_loss: 0.4196 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.92270\n",
      "Epoch 341/350\n",
      "1563/1563 [==============================] - 478s 306ms/step - loss: 0.0894 - acc: 0.9691 - val_loss: 0.4326 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.92270\n",
      "Epoch 342/350\n",
      "1563/1563 [==============================] - 478s 306ms/step - loss: 0.0904 - acc: 0.9680 - val_loss: 0.4376 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.92270\n",
      "Epoch 343/350\n",
      "1563/1563 [==============================] - 479s 306ms/step - loss: 0.0922 - acc: 0.9679 - val_loss: 0.4124 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.92270\n",
      "Epoch 344/350\n",
      "1563/1563 [==============================] - 473s 302ms/step - loss: 0.0883 - acc: 0.9692 - val_loss: 0.4061 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.92270\n",
      "Epoch 345/350\n",
      "1563/1563 [==============================] - 481s 307ms/step - loss: 0.0881 - acc: 0.9683 - val_loss: 0.4223 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00345: val_acc did not improve from 0.92270\n",
      "Epoch 346/350\n",
      "1563/1563 [==============================] - 478s 306ms/step - loss: 0.0925 - acc: 0.9675 - val_loss: 0.4090 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.92270\n",
      "Epoch 347/350\n",
      "1563/1563 [==============================] - 456s 292ms/step - loss: 0.0897 - acc: 0.9681 - val_loss: 0.4196 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.92270\n",
      "Epoch 348/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0908 - acc: 0.9682 - val_loss: 0.4317 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.92270\n",
      "Epoch 349/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0875 - acc: 0.9697 - val_loss: 0.3989 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.92270\n",
      "Epoch 350/350\n",
      "1563/1563 [==============================] - 444s 284ms/step - loss: 0.0902 - acc: 0.9685 - val_loss: 0.4206 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.92270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                                           batch_size=batch_size),\n",
    "                              epochs=epochs, \n",
    "                              validation_data=(X_val, y_val), \n",
    "                              workers=4,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 30s 3ms/step\n",
      "Val loss: 0.42060791709460316\n",
      "Val accuracy: 0.9185\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(X_val, y_val, verbose=1)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_train_history(train_history, y_label = 'Accuracy', train_metric = 'acc', val_metric = 'val_acc'):\n",
    "    # plot training history\n",
    "    plt.plot(history.history[train_metric])\n",
    "    plt.plot(history.history[val_metric])\n",
    "    plt.title('Training history')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history, y_label = 'Loss', train_metric = 'loss', val_metric = 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Weight to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model weights to SavedModel/cifar10-cnn-allconv-0.9185.h5\n"
     ]
    }
   ],
   "source": [
    "filename = 'SavedModel/cifar10-cnn-allconv-{}.h5'.format(score)\n",
    "model.save_weights(filename)\n",
    "print('Saved model weights to ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(best_weights_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'input/test'\n",
    "test_ids = list(range(1, 300001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([np.array(Image.open(test_dir + '/' + str(test_id) + '.png' )) for test_id in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ class_to_label[prediction[i]] for i in range(len(prediction))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(data = { 'id': test_ids, 'label': labels }, columns = [ 'id', 'label' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('output/submission-{}.csv'.format(score), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
